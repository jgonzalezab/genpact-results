{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Approach\n",
    "This notebook contains the code submitted as final in the Genpact Machine Learning Hackathon. The software used is:\n",
    "* R version 3.5.1\n",
    "    * Caret package 6.0-80\n",
    "    * Metrics package 0.1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meal based approach\n",
    "In this approach we fit a model for each meal ID. We work under the assumption that the same type of meal follow the same beahviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv('Data/train.csv')\n",
    "trainCenter <- read.csv('Data/fulfilment_center_info.csv')\n",
    "trainMeal <- read.csv('Data/meal_info.csv')\n",
    "test <- read.csv('Data/test_QoiMO9B.csv')\n",
    "submission <- read.csv('Data/sample_submission_hSlSoT6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data engineering (Delete ID and factorize some caterogical features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train$id <- NULL # Delete id\n",
    "train$emailer_for_promotion <- factor(train$emailer_for_promotion) # Factorize\n",
    "train$homepage_featured <- factor(train$homepage_featured) # Factorize\n",
    "\n",
    "test$emailer_for_promotion <- factor(test$emailer_for_promotion) # Factorize\n",
    "test$homepage_featured <- factor(test$homepage_featured) # Factorize\n",
    "\n",
    "trainCenter$city_code <- factor(trainCenter$city_code) # Factorize\n",
    "trainCenter$region_code <- factor(trainCenter$region_code) # Factorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join datasets by center_id and factorize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEF <- merge(train, trainCenter, by = 'center_id')\n",
    "trainDEF$center_id <- factor(trainDEF$center_id) # Factorize\n",
    "\n",
    "testDEF <- merge(test, trainCenter, by = 'center_id')\n",
    "testDEF$center_id <- factor(testDEF$center_id) # Factorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEF <- trainDEF[, c(1:7, 9:ncol(trainDEF), 8)]\n",
    "testDEF <- testDEF[, c(2, 1, 3:ncol(testDEF))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split the train set based on the meal ID, then for each meal ID we'll split the subset into train and test (the last 10 weeks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBYmeal <- list()\n",
    "for(meal in unique(trainDEF$meal_id)) {\n",
    "  \n",
    "  auxDF <- trainDEF[trainDEF$meal_id == meal, -3] # Delete meal_id column\n",
    "  \n",
    "  trainBYmeal[[as.character(meal)]][['train']] <- auxDF[auxDF$week %in% 1:135, ]\n",
    "  trainBYmeal[[as.character(meal)]][['test']] <- auxDF[auxDF$week %in% 136:145, ]\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function RMSLE is not included in caret so we need to define it manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSLECaretFunc <- function(data, lev = NULL, model = NULL) {\n",
    "  \n",
    "  rmsleCaret <- Metrics::rmsle(data$obs, data$pred)\n",
    "  c(RMSLEcaret = -rmsleCaret)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate and save the standard prediction, augmented by 1.10 and reduced by 0.9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_1 <- submission\n",
    "submission_1 <- cbind.data.frame(submission_1,\n",
    "                                 num_ordersReduced = rep(0, nrow(submission_1)),\n",
    "                                 num_ordersAugmented = rep(0, nrow(submission_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to create a csv saving the RSMLE achieved for each meal ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics <- data.frame(meal = rep(0, length(trainBYmeal)),\n",
    "                      RMSLENormal = rep(0, length(trainBYmeal)),\n",
    "                      RMSLEreduced = rep(0, length(trainBYmeal)),\n",
    "                      RMSLEAugmented = rep(0, length(trainBYmeal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the models (ranger implementation of Random Forests), the process is the following:\n",
    "* Iterate over each meal ID\n",
    "    * Find optimal hyperparameters by validation and calculate RMSLE on test\n",
    "    * Once the optimal hyperparameters are known fit the model on all the train data (for that ID)\n",
    "    * Make the predictions\n",
    "\n",
    "During the process we update the RMSLE table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(15122018)\n",
    "ctrl <- trainControl(method = 'cv',\n",
    "                     number = 3,\n",
    "                     summaryFunction = RMSLECaretFunc)\n",
    "\n",
    "for(i in 1:length(trainBYmeal)) {\n",
    "  \n",
    "  elemMeal <- trainBYmeal[[i]]\n",
    "  \n",
    "  # Find optimal paramaters \n",
    "  model <- suppressMessages(train(num_orders ~ .,\n",
    "                                  data = elemMeal[['train']],\n",
    "                                  method = 'ranger',\n",
    "                                  trControl = ctrl,\n",
    "                                  tuneLength = 2,\n",
    "                                  metric = 'RMSLEcaret'))\n",
    "  \n",
    "  optmParam <- model$bestTune\n",
    "  \n",
    "  # Predictions over the pseudo test set\n",
    "  predsPseudo <- predict(model, elemMeal[['test']][, -11])\n",
    "  \n",
    "  # Update metrics CSV\n",
    "  metrics[i, 1] <- names(trainBYmeal[i])\n",
    "  metrics[i, 2] <- Metrics::rmsle(predsPseudo, elemMeal[['test']][, 11])\n",
    "  metrics[i, 3] <- Metrics::rmsle(predsPseudo, elemMeal[['test']][, 11] * 0.9)\n",
    "  metrics[i, 4] <- Metrics::rmsle(predsPseudo, elemMeal[['test']][, 11] * 1.1)\n",
    "  \n",
    "  # Fit final model\n",
    "  modelFinal <- suppressMessages(train(num_orders ~ .,\n",
    "                                       data = rbind.data.frame(elemMeal[['train']],\n",
    "                                                               elemMeal[['test']]),\n",
    "                                       method = 'ranger',\n",
    "                                       trControl = trainControl(method = 'none',\n",
    "                                                                summaryFunction = RMSLECaretFunc),\n",
    "                                       tuneGrid = optmParam,\n",
    "                                       metric = 'RMSLEcaret'))\n",
    "  \n",
    "  # Final predictions over the real test set\n",
    "  testAUX <- testDEF[testDEF$meal_id == as.numeric(names(trainBYmeal[i])),\n",
    "                     -4]\n",
    "  predsFinal <- predict(modelFinal, testAUX[, -1])\n",
    "  testAUX$preds <- predsFinal\n",
    "  \n",
    "  for (j in 1:nrow(testAUX)) {\n",
    "    \n",
    "    submission_1[submission_1$id == testAUX[j, 'id'], 'num_orders'] <-\n",
    "      testAUX[j, 'preds']\n",
    "    \n",
    "    submission_1[submission_1$id == testAUX[j, 'id'], 'num_ordersReduced'] <-\n",
    "      testAUX[j, 'preds'] * 0.9\n",
    "    \n",
    "    submission_1[submission_1$id == testAUX[j, 'id'], 'num_ordersAugmented'] <-\n",
    "      testAUX[j, 'preds'] * 1.1\n",
    "    \n",
    "  } \n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions and its RMSE values as csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(submission_1, file = 'submission_1.csv', row.names = FALSE)\n",
    "write.csv(metrics, file = 'metrics.csv', row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once generated these files we can make submissions based on:\n",
    "* Original preds: with no changes at all\n",
    "* Reduced preds: Multiplied by 0.9\n",
    "* Augmented preds: Multiplied by 1.10\n",
    "* Combined preds: Select the prediction for each meal ID based on the RMSLE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics <- read.csv('metrics.csv')\n",
    "submission_1 <- read.csv('submission_1.csv')\n",
    "\n",
    "# Original preds\n",
    "preds_1_sub <- submission_1[, c(1, 2)]\n",
    "write.csv(preds_1_sub, 'preds_1_sub.csv', row.names = FALSE) \n",
    "\n",
    "# Reduced preds\n",
    "preds_2_sub <- submission_1[, c(1, 3)]\n",
    "colnames(preds_2_sub)[2] <- 'num_orders'\n",
    "write.csv(preds_2_sub, 'preds_2_sub.csv', row.names = FALSE)\n",
    "\n",
    "# Augmented preds\n",
    "preds_3_sub <- submission_1[, c(1, 4)]\n",
    "colnames(preds_3_sub)[2] <- 'num_orders'\n",
    "write.csv(preds_3_sub, 'preds_3_sub.csv', row.names = FALSE)\n",
    "\n",
    "# Combined preds (test dataframe needed)\n",
    "preds_4_sub <- submission_1[, c(1, 2)]\n",
    "preds_4_sub[, 2] <- rep(0, nrow(preds_4_sub))\n",
    "\n",
    "metricsMins <- data.frame(meal = metrics[, 1],\n",
    "                          whichMin = apply(metrics[, -1], 1, which.min))\n",
    "\n",
    "for(i in preds_4_sub$id) {\n",
    "  \n",
    "  mealFORid <- test[test$id == i, 'meal_id']\n",
    "  bestPred <- metricsMins[metricsMins$meal == mealFORid, 2]\n",
    "  \n",
    "  preds_4_sub[preds_4_sub$id == i, 'num_orders'] <-\n",
    "    submission_1[submission_1$id == i, bestPred + 1]\n",
    "  \n",
    "}\n",
    "\n",
    "write.csv(preds_4_sub, 'preds_4_sub.csv', row.names = FALSE) # LB: 58.3519"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center based approach\n",
    "In this approach we fit a model for each center ID. We work under the assumption that each center has its own behaviour patterns based on the location, country, people nearby...\n",
    "\n",
    "(The process its similar to the previous one and there are a lot of of code repetition which is not a good practice. My justification is that I didn't have enough time to write nice code and, to maint the beauty of the original script, I decided not to change anything)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv('Data/train.csv')\n",
    "trainCenter <- read.csv('Data/fulfilment_center_info.csv')\n",
    "trainMeal <- read.csv('Data/meal_info.csv')\n",
    "test <- read.csv('Data/test_QoiMO9B.csv')\n",
    "submission <- read.csv('Data/sample_submission_hSlSoT6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data engineering (Delete ID and factorize some caterogical features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train$id <- NULL # Delete id\n",
    "train$emailer_for_promotion <- factor(train$emailer_for_promotion) # Factorize\n",
    "train$homepage_featured <- factor(train$homepage_featured) # Factorize\n",
    "\n",
    "test$emailer_for_promotion <- factor(test$emailer_for_promotion) # Factorize\n",
    "test$homepage_featured <- factor(test$homepage_featured) # Factorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join datasets by meal_id and factorize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEF <- merge(train, trainMeal, by = 'meal_id')\n",
    "trainDEF$meal_id <- factor(trainDEF$meal_id) # Factorize\n",
    "\n",
    "testDEF <- merge(test, trainMeal, by = 'meal_id')\n",
    "testDEF$meal_id <- factor(testDEF$meal_id) # Factorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEF <- trainDEF[, c(1:7, 9:ncol(trainDEF), 8)]\n",
    "testDEF <- testDEF[, c(2, 1, 3:ncol(testDEF))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split the train set based on the center ID, then for each meal ID we'll split the subset into train and test (the last 10 weeks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBYcenter <- list()\n",
    "for(center in unique(trainDEF$center_id)) {\n",
    "  \n",
    "  auxDF <- trainDEF[trainDEF$center_id == center, -3] # Delete center_id column\n",
    "  \n",
    "  trainBYcenter[[as.character(center)]][['train']] <- auxDF[auxDF$week %in% 1:135, ]\n",
    "  trainBYcenter[[as.character(center)]][['test']] <- auxDF[auxDF$week %in% 136:145, ]\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate and save the standard prediction, augmented by 1.10 and reduced by 0.9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_1 <- submission\n",
    "submission_1 <- cbind.data.frame(submission_1,\n",
    "                                 num_ordersReduced = rep(0, nrow(submission_1)),\n",
    "                                 num_ordersAugmented = rep(0, nrow(submission_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to create a csv saving the RSMLE achieved for a each center ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics <- data.frame(center = rep(0, length(trainBYcenter)),\n",
    "                      RMSLENormal = rep(0, length(trainBYcenter)),\n",
    "                      RMSLEreduced = rep(0, length(trainBYcenter)),\n",
    "                      RMSLEAugmented = rep(0, length(trainBYcenter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the models (ranger implementation of Random Forests), the process is the following:\n",
    "* Iterate over each center ID\n",
    "    * Find optimal hyperparameters by validation and calculate RMSLE on test\n",
    "    * Once the optimal hyperparameters are known fit the model on all the train data (for that ID)\n",
    "    * Make the predictions\n",
    "\n",
    "During the process we update the RMSLE table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(15122018)\n",
    "ctrl <- trainControl(method = 'cv',\n",
    "                     number = 3,\n",
    "                     summaryFunction = RMSLECaretFunc)\n",
    "\n",
    "for(i in 1:length(trainBYcenter)) {\n",
    "  \n",
    "  elemCenter <- trainBYcenter[[i]]\n",
    "  \n",
    "  # Find optimal paramaters\n",
    "  model <- train(num_orders ~ .,\n",
    "                 data = elemCenter[['train']],\n",
    "                 method = 'ranger',\n",
    "                 trControl = ctrl,\n",
    "                 tuneLength = 2,\n",
    "                 metric = 'RMSLEcaret')\n",
    "  \n",
    "  optmParam <- model$bestTune\n",
    "  \n",
    "  # Predictions over the pseudo test set\n",
    "  predsPseudo <- predict(model, elemCenter[['test']][, -11])\n",
    "  \n",
    "  # Update metrics CSV\n",
    "  metrics[i, 1] <- names(trainBYcenter[i])\n",
    "  metrics[i, 2] <- Metrics::rmsle(predsPseudo, elemCenter[['test']][, 'num_orders'])\n",
    "  metrics[i, 3] <- Metrics::rmsle(predsPseudo, elemCenter[['test']][, 'num_orders'] * 0.9)\n",
    "  metrics[i, 4] <- Metrics::rmsle(predsPseudo, elemCenter[['test']][, 'num_orders'] * 1.1)\n",
    "  \n",
    "  # Fit final model\n",
    "  modelFinal <- train(num_orders ~ .,\n",
    "                      data = rbind.data.frame(elemCenter[['train']],\n",
    "                                              elemCenter[['test']]),\n",
    "                      method = 'ranger',\n",
    "                      trControl = trainControl(method = 'none',\n",
    "                                               summaryFunction = RMSLECaretFunc),\n",
    "                      tuneGrid = optmParam,\n",
    "                      metric = 'RMSLEcaret')\n",
    "  \n",
    "  # Final predictions over the real test set\n",
    "  testAUX <- testDEF[testDEF$center_id == as.numeric(names(trainBYcenter[i])),\n",
    "                     -4]\n",
    "  predsFinal <- predict(modelFinal, testAUX[, -1])\n",
    "  testAUX$preds <- predsFinal\n",
    "  \n",
    "  for (j in 1:nrow(testAUX)) {\n",
    "    \n",
    "    submission_1[submission_1$id == testAUX[j, 'id'], 'num_orders'] <-\n",
    "      testAUX[j, 'preds']\n",
    "    \n",
    "    submission_1[submission_1$id == testAUX[j, 'id'], 'num_ordersReduced'] <-\n",
    "      testAUX[j, 'preds'] * 0.9\n",
    "    \n",
    "    submission_1[submission_1$id == testAUX[j, 'id'], 'num_ordersAugmented'] <-\n",
    "      testAUX[j, 'preds'] * 1.1\n",
    "    \n",
    "  } \n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions and its RMSE values as csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(submission_1, file = 'submission_1_2nd.csv', row.names = FALSE)\n",
    "write.csv(metrics, file = 'metrics_2nd.csv', row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once generated these files we can make submissions based on:\n",
    "* Original preds: with no changes at all\n",
    "* Reduced preds: Multiplied by 0.9\n",
    "* Augmented preds: Multiplied by 1.10\n",
    "* Combined preds: Select the prediction for each meal ID based on the RMSLE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics <- read.csv('metrics_2nd.csv')\n",
    "submission_1 <- read.csv('submission_1_2nd.csv')\n",
    "\n",
    "# Original preds\n",
    "preds_1_sub <- submission_1[, c(1, 2)]\n",
    "write.csv(preds_1_sub, 'preds_1_sub_2nd.csv', row.names = FALSE) \n",
    "\n",
    "# Reduced preds\n",
    "preds_2_sub <- submission_1[, c(1, 3)]\n",
    "colnames(preds_2_sub)[2] <- 'num_orders'\n",
    "write.csv(preds_2_sub, 'preds_2_sub_2nd.csv', row.names = FALSE) \n",
    "\n",
    "# Augmented preds\n",
    "preds_3_sub <- submission_1[, c(1, 4)]\n",
    "colnames(preds_3_sub)[2] <- 'num_orders'\n",
    "write.csv(preds_3_sub, 'preds_3_sub_2nd.csv', row.names = FALSE) \n",
    "\n",
    "# Combined preds (test dataframe needed)\n",
    "preds_4_sub <- submission_1[, c(1, 2)]\n",
    "preds_4_sub[, 2] <- rep(0, nrow(preds_4_sub))\n",
    "\n",
    "metricsMins <- data.frame(center = metrics[, 1],\n",
    "                          whichMin = apply(metrics[, -1], 1, which.min))\n",
    "\n",
    "for(i in preds_4_sub$id) {\n",
    "  \n",
    "  centerFORid <- test[test$id == i, 'center_id']\n",
    "  bestPred <- metricsMins[metricsMins$center == centerFORid, 2]\n",
    "  \n",
    "  preds_4_sub[preds_4_sub$id == i, 'num_orders'] <-\n",
    "    submission_1[submission_1$id == i, bestPred + 1]\n",
    "  \n",
    "}\n",
    "\n",
    "write.csv(preds_4_sub, 'preds_4_sub_2nd.csv', row.names = FALSE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Ensemble\n",
    "The best results were obtained by the reduced predictions, that's why the final submission is a simple ensemble of these two predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstApproachPREDS <- read.csv('preds_2_sub.csv') # Reduced preds (meal approach)\n",
    "secondApproachPREDS <- read.csv('preds_2_sub_2nd.csv') # Reduced preds (center approach)\n",
    "\n",
    "ensemble <- data.frame(id = firstApproachPREDS$id,\n",
    "                       num_orders = rowMeans(data.frame(firstApproachPREDS$num_orders,\n",
    "                                                        secondApproachPREDS$num_orders)))\n",
    "\n",
    "write.csv(ensemble, file = 'ensembleFS.csv', row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
